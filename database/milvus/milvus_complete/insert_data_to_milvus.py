from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility
import torch
import numpy as np
import time
from tqdm import tqdm
from transformers import BertTokenizer, AlbertModel

def load_data_file(file_path):
    """åŠ è½½æ–‡æœ¬æ•°æ®
    Args:
        file_path:æ–‡æœ¬è·¯å¾„
    Return: 
        lines:æ–‡æœ¬æ•°æ®
    """
    lines = []
    with open(file_path, "r", encoding='utf-8')as f:
        for line in f.readlines():
            lines.append(line.strip('\n'))
        f.close()
    return lines

def create_connection():
    """å»ºç«‹milvusè¿æ¥(milvusé»˜è®¤ä¸ºè¿æ¥æ± å½¢å¼)
    """
    print(f"\nåˆ›å»ºMilvusè¿æ¥...")
    connections.connect(host='localhost', port='19530')
    print(f"\nå½“å‰æ‰€è¿æ¥æ•°æ®åº“ä¸­å«æœ‰çš„é›†åˆä¸º:")
    print(utility.list_collections())   # è¿”å›å€¼ä¸ºé›†åˆå(str)ç»„æˆçš„list

def create_milvus_collection(collection_name, dim):
    """åˆ›å»ºmilvusé›†åˆ
    Args:
        collection_name: é›†åˆåç§°
        dim: è¯å‘é‡å­—æ®µçš„ç»´åº¦
    Return:
        collection: åˆ›å»ºçš„milvusé›†åˆ
    """
    if utility.has_collection(collection_name):
        utility.drop_collection(collection_name)
    
    fields = [
            FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=False),
            FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=500),   
            FieldSchema(name="text_vector", dtype=DataType.FLOAT_VECTOR, dim=dim),
    ]
    schema = CollectionSchema(fields=fields, description='search text')
    collection = Collection(name=collection_name, schema=schema)
    
    index_params = {
        'metric_type': "COSINE",
        'index_type': "HNSW",
        'params': {"nlist": 1024, 'efConstruction': 10, 'M':60}
    }
    collection.create_index(field_name='text_vector', index_params=index_params)
    return collection

class Convert_Batch_Text_2_Vector:
    """å°†æ–‡æœ¬ä»¥batchæ–¹å¼è½¬ä¸ºè¯å‘é‡,æ³¨æ„ä»¥batchæ–¹å‘è½¬è¯å‘é‡éœ€è¦æ¶ˆé™¤paddingçš„å½±å“
    """
    tokenizer = BertTokenizer.from_pretrained("clue/albert_chinese_tiny")
    model = AlbertModel.from_pretrained("clue/albert_chinese_tiny")
    
    def __init__(self):
        pass
    def convert_batch_to_embed(self, text_data, batch_size, collection):
        """å°†æ–‡æœ¬ä»¥batchæ–¹å¼è½¬ä¸ºè¯å‘é‡
        Args:
            text_data: å¾…è½¬åŒ–çš„æ–‡æœ¬,æ•°æ®ç±»å‹è¦æ±‚ä¸ºlist
            batch_size: batchå¤§å°
            collection: å‡†å¤‡æ’å…¥çš„milvusé›†åˆ
        Return:
            None: ç”±äºæ‰§è¡Œçš„æ˜¯æ’å…¥æ“ä½œ,æ— è¿”å›å€¼
        """
        # è·å–å¾…è½¬åŒ–æ–‡æœ¬çš„é•¿åº¦ï¼Œç”¨äºåšbatchåˆ‡åˆ†
        num_texts = len(text_data)
        print(f"\nå¼€å§‹è¿›è¡Œè¯å‘é‡æ‰¹é‡è½¬åŒ–ï¼Œå¹¶æŒ‰æ‰¹æ¬¡å†™å…¥Milvusçš„{collection.name}é›†åˆä¸­---\n")
        # è®°å½•è¯å‘é‡è½¬åŒ–å¼€å§‹æ—¶é—´
        start_time = time.time() 
        for i in tqdm(range(0, num_texts, batch_size)):
            batch_texts = text_data[i:i + batch_size]
            ids = np.arange(i, min(i + batch_size, num_texts)).tolist()
            encoded_texts = self.tokenizer(batch_texts, return_tensors='pt', padding=True)
            with torch.no_grad():
                # é€šè¿‡æ¨¡å‹è·å–æ–‡æœ¬çš„éšè—çŠ¶æ€
                last_hidden_state = self.model(**encoded_texts).last_hidden_state
                # è·å–æ³¨æ„åŠ›æ©ç 
                attention_mask = encoded_texts["attention_mask"]
                # å°†éšè—çŠ¶æ€ä¸æ³¨æ„åŠ›æ©ç ç›¸ä¹˜ï¼Œç”¨äºæ¶ˆé™¤paddingçš„å½±å“
                last_hidden_state = last_hidden_state * attention_mask.unsqueeze(-1)
                # å¯¹éšè—çŠ¶æ€æ±‚å’Œï¼Œç”¨äºè·å¾—æ•´ä¸ªæ–‡æœ¬çš„è¡¨ç¤º
                sum_hidden_state = last_hidden_state.sum(dim=1).squeeze()
                # é€šè¿‡æ³¨æ„åŠ›æ©ç çš„å’Œè¿›è¡Œå½’ä¸€åŒ–
                output = sum_hidden_state / attention_mask.sum(dim=1, keepdim=True)
                # è½¬åŒ–ä¸ºnumpyæ•°ç»„
                output = output.numpy()
            # å½’ä¸€åŒ–è¾“å‡ºå‘é‡ï¼Œä»¥ä¾¿å‘é‡çš„æ¨¡é•¿ä¸º1
            output = output / np.linalg.norm(output, axis=1, keepdims=True).tolist()
            collection.insert([ids, batch_texts, output.tolist()])
        end_time = time.time()
        total_time = end_time - start_time
        print("*" * 30)
        print(f"æ­å–œğŸ‰,æ•°æ®å·²å…¨éƒ¨å†™å…¥Milvusçš„{collection.name}é›†åˆä¸­,å…±è€—æ—¶{total_time}sã€‚")
        print("*" * 30)

if __name__ == '__main__':
    # åŠ è½½æ•°æ®
    file_path = "new_ç°ä»£æ±‰è¯­å¸¸ç”¨è¯æ±‡.txt"
    text_data = load_data_file(file_path)
    
    # å»ºç«‹milvusè¿æ¥
    create_connection()
    
    # åˆ›å»ºmilvusé›†åˆ
    milvus_collection = create_milvus_collection('search_article_in_medium', 312)
    
    # è¯å‘é‡è½¬åŒ–ç±»çš„å®ä¾‹åŒ–
    albert_embed_model = Convert_Batch_Text_2_Vector()
    
    # å°†æ–‡æœ¬æ•°æ®è½¬åŒ–ä¸ºè¯å‘é‡ï¼Œå¹¶ä»¥batchå½¢å¼å†™å…¥milvusé›†åˆ
    albert_embed_model.convert_batch_to_embed(text_data, 128, milvus_collection)